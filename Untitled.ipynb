{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c248d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting classifier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile classifier.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "def pre_process(fid=None):\n",
    "    fid = Path(fid)\n",
    "    df = pd.read_csv('gender-classifier-DFE-791531.csv',  encoding='latin-1')\n",
    "    girls_tweets = df[df['gender']=='female'][['text','gender']]\n",
    "    boys_tweets =  df[df['gender']=='male'][['text','gender']]\n",
    "    df = pd.concat([girls_tweets,boys_tweets])\n",
    "    df['binary'] = pd.get_dummies(df.gender, prefix='gender')['gender_female']\n",
    "    df = df[['text','gender']]\n",
    "    plt.bar(['women','men'],height=np.bincount(df['binary']))\n",
    "\n",
    "    train = df.sample(frac=0.8,random_state=43)\n",
    "    test = df.drop(train.index)\n",
    "    valid = train.sample(frac=0.1, random_state=43)\n",
    "    train = train.drop(valid.index)\n",
    "\n",
    "    train.to_csv('gender_text_train.csv', mode='w', index=False)\n",
    "    test.to_csv('gender_text_test.csv', mode='w', index=False)\n",
    "    valid.to_csv('gender_text_valid.csv', mode='w', index=False)\n",
    "    \n",
    "def train_hf_api(args):\n",
    "\n",
    "    if args.login:\n",
    "        sub_args = ('autonlp login --api-key  ')\n",
    "        os.system(sub_args+args.api_key)\n",
    "    \n",
    "    if args.send:\n",
    "        sub_args = f'autonlp upload '\n",
    "        sub_args+= f' --project {args.project}'\n",
    "        sub_args+= f' --split {args.split}'\n",
    "        sub_args+= f' --col_mapping {args.col_mapping}'\n",
    "        sub_args+= f' --files {args.files}'\n",
    "        os.system(sub_args)\n",
    "        \n",
    "        \n",
    "    if args.make:\n",
    "        sub_args = f'autonlp create_project '\n",
    "        sub_args+= f' --name {args.name}'\n",
    "        sub_args+= f' --language {args.language}'\n",
    "        sub_args+= f' --task {args.task}'\n",
    "        sub_args+= f' --max_models {args.max_models}'\n",
    "        os.system(sub_args)\n",
    "\n",
    "    if args.train:\n",
    "        sub_args = f'autonlp train '\n",
    "        sub_args+= f' --project {args.project}'\n",
    "        os.system(sub_args)\n",
    "\n",
    "def inference(json_fid=None):\n",
    "    with open(json_fid,'r') as fid:\n",
    "        text_dict = json.load(json_fid)\n",
    "        \n",
    "    # load some model eg. model = torch.loadstatedict(model.pth)\n",
    "    # for key in text_dict:\n",
    "    #    prediction = model.predict(text_dict[key])\n",
    "    #    text_dict[pred_gender]=prediction\n",
    "    # json.dump(text_dict)\n",
    "    # \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e325c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6a0f79bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import classifier\n",
    "import argparse\n",
    "\n",
    "\n",
    "#hugging face api autonlp argugments (passed back to lower level in stack) \n",
    "\n",
    "parser = argparse.ArgumentParser(description='Training Calssifier ')\n",
    "\n",
    "\n",
    "parser.add_argument('--input csv', default='gender-classifier-DFE-791531.csv', \n",
    "                    type=str, help='relative loacation of input csv for training')\n",
    "parser.add_argument('--project', default='gender_class', type=str, help='poject name')\n",
    "\n",
    "\n",
    "parser.add_argument('--split', default='train', type=str, help='dataset split')\n",
    "\n",
    "parser.add_argument('--col_mapping',default=None, type=str, help='text:text, label:target')\n",
    "\n",
    "parser.add_argument('--files',default='gender_text_train.csv', type=str, \n",
    "                    help='formated csv only 2 colls one for text one for target')\n",
    "\n",
    "parser.add_argument('--api_key', default=None, type=str, help='api key from hugging_face account')\n",
    "parser.add_argument('--resize', type=int, help='Resizes images by percentage as scalar')\n",
    "\n",
    "\n",
    "parser.add_argument('--name', type=str, help='project name hugging face')\n",
    "\n",
    "parser.add_argument('--language', type=str, help='lang in eg [en,sp,fr]')\n",
    "\n",
    "parser.add_argument('--task', type=str, default='binary_classification',\n",
    "                    help='Resizes images by percentage as scalar')\n",
    "parser.add_argument('--max_models', type=int, default=2, help= 'nuber of trainable models')\n",
    "parser.add_argument('--create_project', action='store_true',  help='create_new hf project')\n",
    "\n",
    "#meta args-- directing sub process\n",
    "parser.add_argument('--hugging_face', action='store_true', help='uses hugging face api to train model')\n",
    "parser.add_argument('--send', action='store_true',  help='if entered will try to sen .csv')\n",
    "parser.add_argument('--login', action='store_true',  help='if entered will try to sen .csv')\n",
    "parser.add_argument('--make', action='store_true',  help='create_new hf project')\n",
    "parser.add_argument('--train', action='store_true',  help='create_new hf project')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    if args.hugging_face:\n",
    "        print(args.api_key)\n",
    "        classifier.train_hf_api(args)\n",
    "    \n",
    "        print('Model trianing using autonlp (hugging face api)')\n",
    "       \n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "66a704df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "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\n",
      "> \u001b[1mINFO    üóù Successfully logged in as Frida\u001b[0m\n",
      "> \u001b[1mINFO    üóù Storing credentials in:  /Users/fridades/.autonlp\u001b[0m\n",
      "Welcome to ü§ó AutoNLP! Start by creating a project: \u001b[91mautonlp create_project\u001b[0m\n",
      "Model trianing using autonlp (hugging face api)\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py --hugging_face --login --api_key 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 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b82de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bd482c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "None\n",
      "> \u001b[1mINFO    Uploading files for project: gender_class\u001b[0m\n",
      "> \u001b[1mINFO    üóù Retrieving credentials from config...\u001b[0m\n",
      "> \u001b[1mINFO    ‚òÅ Retrieving project 'gender_class' from AutoNLP...\u001b[0m\n",
      "> \u001b[1mINFO    üîÑ Refreshing project status...\u001b[0m\n",
      "> \u001b[1mINFO    üîÑ Refreshing uploaded files information...\u001b[0m\n",
      "> \u001b[1mINFO    üîÑ Refreshing models information...\u001b[0m\n",
      "> \u001b[1mINFO    üîÑ Refreshing cost information...\u001b[0m\n",
      "> \u001b[1mINFO    ‚úÖ Successfully loaded project: 'gender_class'!\u001b[0m\n",
      "> \u001b[1mINFO    Mapping: {'text': 'text', 'gender': 'target'}\u001b[0m\n",
      "> \u001b[1mINFO    [1/1] üîé Validating gender_text_train.csv and column mapping...\u001b[0m\n",
      "Using custom data configuration default-274ad4e6cc812bc7\n",
      "Reusing dataset csv (/Users/fridades/.cache/huggingface/datasets/csv/default-274ad4e6cc812bc7/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
      "> \u001b[1mINFO    [1/1] üì¶ Copying gender_text_train.csv to /Users/fridades/.huggingface/autonlp/projects/Frida/autonlp-data-gender_class/raw/gender_text_train.csv...\u001b[0m\n",
      "> \u001b[1mINFO    ‚òÅ Uploading files to the dataset hub...\u001b[0m\n",
      "> \u001b[1mINFO    ‚ùî Files did not change since last upload!\u001b[0m\n",
      "üéâ Yupee! Your files have been uploaded.\n",
      "Once you're done, starting a training here: \u001b[91mautonlp train --project gender_class\u001b[0m\n",
      "usage: autonlp <command> [<args>]\n",
      "\n",
      "positional arguments:\n",
      "  {login,create_project,project_info,upload,train,metrics,list_projects,predict,estimate,evaluate,benchmark}\n",
      "                        commands\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version, -v         Display AutoNLP version\n",
      "\n",
      "For more information about a command, run: `autonlp <command> --help`\n",
      "Model trianing using autonlp (hugging face api)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c933c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown \n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fa8ee8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not even looking forward to this drive to Attl...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@CorsoJo yes! And at the hotel I'm looking at,...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's great that more ppl love dogs &amp;amp; cats ...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>face is boiling, hands and feet are freezing_√ô...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@TypicalGamer Hey my name is Travis and I woul...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>@brokentelephan sorry for ignoring you so much...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>Like the title one of her songs @elliegoulding...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>It had been so long, the box actually had a th...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>@_blowNEmind I have a coupe I only needed my 2...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>Josh Norman is the best cb right now</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1032 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  gender\n",
       "0     Not even looking forward to this drive to Attl...  female\n",
       "1     @CorsoJo yes! And at the hotel I'm looking at,...  female\n",
       "2     It's great that more ppl love dogs &amp; cats ...  female\n",
       "3     face is boiling, hands and feet are freezing_√ô...  female\n",
       "4     @TypicalGamer Hey my name is Travis and I woul...    male\n",
       "...                                                 ...     ...\n",
       "1027  @brokentelephan sorry for ignoring you so much...    male\n",
       "1028  Like the title one of her songs @elliegoulding...    male\n",
       "1029  It had been so long, the box actually had a th...  female\n",
       "1030  @_blowNEmind I have a coupe I only needed my 2...  female\n",
       "1031               Josh Norman is the best cb right now    male\n",
       "\n",
       "[1032 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "https://drive.google.com/file/d/1TdkdylFnlI1efahselb-y5o8hI-9vZza/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846e192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
